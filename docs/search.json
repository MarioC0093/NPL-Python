[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pipeline para el Procesamiento del Lenguaje Natural (NPL) a través de la librería spaCy",
    "section": "",
    "text": "Leemos el libro El Quijote.\n\n\nCódigo\n# Enviar una solicitud GET a la URL\nresponse = requests.get(\"https://www.gutenberg.org/cache/epub/2000/pg2000.txt\")\n\n# Verificar si la solicitud fue exitosa\nif response.status_code == 200:\n    quijote = response.text\n    # print(\"Éxito al leer el texto.\")\nelse:\n    print(\"Error al leer el texto.\")\n\n\nNos ocupamos únicamente de los primeros seis capítulos de la primera parte de El Quijote.\n\n\nCódigo\n### Inicio del primer capítulo\n\n# Palabra objetivo\npalabra_start = \"Primera parte del ingenioso hidalgo don Quijote de la Mancha\"\n\n# Expresión regular para capturar todo lo que va antes de un patrón de  búsqueda\npatron = re.compile(rf\"{palabra_start}\\s*(.*)\", re.DOTALL)\n\ncoincidencia = patron.search(quijote)\n\nif coincidencia:\n    quijote = coincidencia.group(1) # 0 incluye la palabra del search, 1 no lo incluye\n    console.print(\"[bold]Inicio del primer capítulo:\\n\\n[/bold]\", quijote[:251])\n    # print(\"Inicio del texto:\\n\\n\", quijote[:251])\nelse:\n    console.print(\"[bold]Inicio del texto:\\n\\n[/bold]\", quijote[:251])\n    \n\n### Inicio del sépimo capítulo (y final del sexto)\npalabra_end = \"Capítulo VII\"\n\n# patron = re.compile(rf\"(.*)\\b{re.escape(palabra_end)}\\b\", re.DOTALL) # .* es codicioso (\"greedy\"): captura la mayor cantidad posible de caracteres antes de la coincidir con la palabra, captura hasta la última aparición de la palabra buscada\npatron = re.compile(rf\"(.*?)\\b{re.escape(palabra_end)}\\b\", re.DOTALL) # .* es no codicioso (\"lazy\"): captura la menor cantidad posible de caracteres y evitar que el resto del texto cooincida, se detiene en la primera coincidencia\n\ncoincidencia = patron.search(quijote)\n\nif coincidencia:\n    quijote = coincidencia.group(0)\n    console.print(\"[bold]Final del sexto capítulo:\\n\\n[/bold]\", quijote[-231:])\n    quijote = coincidencia.group(1) # Elimino el patrón de búsqueda\nelse:\n    console.print(\"[bold]Final del texto:\\n\\n[/bold]\", quijote[-231:])\n\n\nInicio del primer capítulo:\n\n Capítulo primero. Que trata de la condición y ejercicio del famoso hidalgo\ndon Quijote de la Mancha\n\nEn un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho\ntiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua\n\n\n\nFinal del sexto capítulo:\n\n o el cura en oyendo el nombre— si tal libro hubiera\nmandado quemar; porque su autor fue uno de los famosos poetas del mundo, no\nsólo de España, y fue felicísimo en la tradución de algunas fábulas de\nOvidio.\n\n\n\n\nCapítulo VII\n\n\n\n\n\n\n\n\nWhat’s spaCy? spaCy es una biblioteca gratuita de código abierto para el procesamiento avanzado del lenguaje natural en Python.\nLa librería spaCy se basa en modelos de aprendizaje automático que se entrenaron con grandes cantidades de datos de texto etiquetados.\nDescarga y carga del modelo de lenguaje a través de la librería spaCy:\n\n# !python -m spacy download es_core_news_md\n\n\nimport spacy\nnlp = spacy.load(\"es_core_news_md\")\n\n\n\n\n\nPodemos dividir el texto en párrafos.\n\n\nCódigo\nfor parrafo in list(nlp(quijote).sents)[:3]: # No es necesario pasarlo a una lista, solo para coger un número de ejemplos\n    console.print(\"[blue]\\nSiguiente párrafo:\\n\\n[/blue]\", parrafo)\n    #print(parrafo)\n\n\n\n\nSiguiente párrafo:\n\n Capítulo primero.\n\n\n\nSiguiente párrafo:\n\n Que trata de la condición y ejercicio del famoso hidalgo\ndon Quijote de la Mancha\n\nEn un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho\ntiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua,\nrocín flaco y galgo corredor.\n\n\n\nSiguiente párrafo:\n\n Una olla de algo más vaca que carnero,\nsalpicón las más noches, duelos y quebrantos los sábados, lantejas los\nviernes, algún palomino de añadidura los domingos, consumían las tres\npartes de su hacienda.\n\n\n\n\n\nY los párrafos en palabras.\n\n\nCódigo\nfor parrafo in list(nlp(quijote).sents)[1:2]:\n    console.print(\"[blue]\\nSiguiente párrafo:\\n[/blue]\")\n    # print(colored(\"\\nSiguiente párrafo:\\n\",'blue'))\n    for palabra in parrafo[:5]:\n        print(palabra)\n\n\nSiguiente párrafo:\n\n\n\n\nQue\ntrata\nde\nla\ncondición\n\n\nY separar cada una de las frases.\n\n\nCódigo\ndocumento = nlp(quijote)\nsents = list(documento.sents)[:3]\nsents\n\n\n[Capítulo primero.,\n Que trata de la condición y ejercicio del famoso hidalgo\n don Quijote de la Mancha\n \n En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho\n tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua,\n rocín flaco y galgo corredor.,\n Una olla de algo más vaca que carnero,\n salpicón las más noches, duelos y quebrantos los sábados, lantejas los\n viernes, algún palomino de añadidura los domingos, consumían las tres\n partes de su hacienda.]"
  },
  {
    "objectID": "index.html#ingesta-del-documento",
    "href": "index.html#ingesta-del-documento",
    "title": "Pipeline para el Procesamiento del Lenguaje Natural (NPL) a través de la librería spaCy",
    "section": "",
    "text": "Leemos el libro El Quijote.\n\n\nCódigo\n# Enviar una solicitud GET a la URL\nresponse = requests.get(\"https://www.gutenberg.org/cache/epub/2000/pg2000.txt\")\n\n# Verificar si la solicitud fue exitosa\nif response.status_code == 200:\n    quijote = response.text\n    # print(\"Éxito al leer el texto.\")\nelse:\n    print(\"Error al leer el texto.\")\n\n\nNos ocupamos únicamente de los primeros seis capítulos de la primera parte de El Quijote.\n\n\nCódigo\n### Inicio del primer capítulo\n\n# Palabra objetivo\npalabra_start = \"Primera parte del ingenioso hidalgo don Quijote de la Mancha\"\n\n# Expresión regular para capturar todo lo que va antes de un patrón de  búsqueda\npatron = re.compile(rf\"{palabra_start}\\s*(.*)\", re.DOTALL)\n\ncoincidencia = patron.search(quijote)\n\nif coincidencia:\n    quijote = coincidencia.group(1) # 0 incluye la palabra del search, 1 no lo incluye\n    console.print(\"[bold]Inicio del primer capítulo:\\n\\n[/bold]\", quijote[:251])\n    # print(\"Inicio del texto:\\n\\n\", quijote[:251])\nelse:\n    console.print(\"[bold]Inicio del texto:\\n\\n[/bold]\", quijote[:251])\n    \n\n### Inicio del sépimo capítulo (y final del sexto)\npalabra_end = \"Capítulo VII\"\n\n# patron = re.compile(rf\"(.*)\\b{re.escape(palabra_end)}\\b\", re.DOTALL) # .* es codicioso (\"greedy\"): captura la mayor cantidad posible de caracteres antes de la coincidir con la palabra, captura hasta la última aparición de la palabra buscada\npatron = re.compile(rf\"(.*?)\\b{re.escape(palabra_end)}\\b\", re.DOTALL) # .* es no codicioso (\"lazy\"): captura la menor cantidad posible de caracteres y evitar que el resto del texto cooincida, se detiene en la primera coincidencia\n\ncoincidencia = patron.search(quijote)\n\nif coincidencia:\n    quijote = coincidencia.group(0)\n    console.print(\"[bold]Final del sexto capítulo:\\n\\n[/bold]\", quijote[-231:])\n    quijote = coincidencia.group(1) # Elimino el patrón de búsqueda\nelse:\n    console.print(\"[bold]Final del texto:\\n\\n[/bold]\", quijote[-231:])\n\n\nInicio del primer capítulo:\n\n Capítulo primero. Que trata de la condición y ejercicio del famoso hidalgo\ndon Quijote de la Mancha\n\nEn un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho\ntiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua\n\n\n\nFinal del sexto capítulo:\n\n o el cura en oyendo el nombre— si tal libro hubiera\nmandado quemar; porque su autor fue uno de los famosos poetas del mundo, no\nsólo de España, y fue felicísimo en la tradución de algunas fábulas de\nOvidio.\n\n\n\n\nCapítulo VII"
  },
  {
    "objectID": "index.html#carga-del-modelo",
    "href": "index.html#carga-del-modelo",
    "title": "Pipeline para el Procesamiento del Lenguaje Natural (NPL) a través de la librería spaCy",
    "section": "",
    "text": "What’s spaCy? spaCy es una biblioteca gratuita de código abierto para el procesamiento avanzado del lenguaje natural en Python.\nLa librería spaCy se basa en modelos de aprendizaje automático que se entrenaron con grandes cantidades de datos de texto etiquetados.\nDescarga y carga del modelo de lenguaje a través de la librería spaCy:\n\n# !python -m spacy download es_core_news_md\n\n\nimport spacy\nnlp = spacy.load(\"es_core_news_md\")"
  },
  {
    "objectID": "index.html#fragmentación-de-la-información",
    "href": "index.html#fragmentación-de-la-información",
    "title": "Pipeline para el Procesamiento del Lenguaje Natural (NPL) a través de la librería spaCy",
    "section": "",
    "text": "Podemos dividir el texto en párrafos.\n\n\nCódigo\nfor parrafo in list(nlp(quijote).sents)[:3]: # No es necesario pasarlo a una lista, solo para coger un número de ejemplos\n    console.print(\"[blue]\\nSiguiente párrafo:\\n\\n[/blue]\", parrafo)\n    #print(parrafo)\n\n\n\n\nSiguiente párrafo:\n\n Capítulo primero.\n\n\n\nSiguiente párrafo:\n\n Que trata de la condición y ejercicio del famoso hidalgo\ndon Quijote de la Mancha\n\nEn un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho\ntiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua,\nrocín flaco y galgo corredor.\n\n\n\nSiguiente párrafo:\n\n Una olla de algo más vaca que carnero,\nsalpicón las más noches, duelos y quebrantos los sábados, lantejas los\nviernes, algún palomino de añadidura los domingos, consumían las tres\npartes de su hacienda.\n\n\n\n\n\nY los párrafos en palabras.\n\n\nCódigo\nfor parrafo in list(nlp(quijote).sents)[1:2]:\n    console.print(\"[blue]\\nSiguiente párrafo:\\n[/blue]\")\n    # print(colored(\"\\nSiguiente párrafo:\\n\",'blue'))\n    for palabra in parrafo[:5]:\n        print(palabra)\n\n\nSiguiente párrafo:\n\n\n\n\nQue\ntrata\nde\nla\ncondición\n\n\nY separar cada una de las frases.\n\n\nCódigo\ndocumento = nlp(quijote)\nsents = list(documento.sents)[:3]\nsents\n\n\n[Capítulo primero.,\n Que trata de la condición y ejercicio del famoso hidalgo\n don Quijote de la Mancha\n \n En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho\n tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua,\n rocín flaco y galgo corredor.,\n Una olla de algo más vaca que carnero,\n salpicón las más noches, duelos y quebrantos los sábados, lantejas los\n viernes, algún palomino de añadidura los domingos, consumían las tres\n partes de su hacienda.]"
  },
  {
    "objectID": "index.html#tokenization",
    "href": "index.html#tokenization",
    "title": "Pipeline para el Procesamiento del Lenguaje Natural (NPL) a través de la librería spaCy",
    "section": "2.1 Tokenization",
    "text": "2.1 Tokenization\n\n\nCódigo\ntokens = word_tokenize(text)\nprint(tokens[:10])\n\n\n['Capítulo', 'primero', '.', 'Que', 'trata', 'de', 'la', 'condición', 'y', 'ejercicio']"
  },
  {
    "objectID": "index.html#stop-words",
    "href": "index.html#stop-words",
    "title": "Pipeline para el Procesamiento del Lenguaje Natural (NPL) a través de la librería spaCy",
    "section": "2.2 Stop Words",
    "text": "2.2 Stop Words\n\n\nCódigo\nstop_words = set(stopwords.words('spanish'))\ntokens = [w for w in tokens if w.lower() not in stop_words]\ntokens_ejemplos = tokens\nprint(tokens[:10])\n\n\n['Capítulo', 'primero', '.', 'trata', 'condición', 'ejercicio', 'famoso', 'hidalgo', 'don', 'Quijote']"
  },
  {
    "objectID": "index.html#stemming-and-lemmatization",
    "href": "index.html#stemming-and-lemmatization",
    "title": "Pipeline para el Procesamiento del Lenguaje Natural (NPL) a través de la librería spaCy",
    "section": "2.3 Stemming and Lemmatization",
    "text": "2.3 Stemming and Lemmatization\nhttps://spacy.io/models/es\nhttps://github.com/explosion/spacy-models/releases?q=es_core_web_md&expanded=true\n\n\nCódigo\nstemmer = SnowballStemmer(\"spanish\")\ntokens = [stemmer.stem(palabra) for palabra in tokens]\ntokens[:10]\n\n\n['capitul',\n 'primer',\n '.',\n 'trat',\n 'condicion',\n 'ejercici',\n 'famos',\n 'hidalg',\n 'don',\n 'quijot']"
  },
  {
    "objectID": "index.html#pos-tagging",
    "href": "index.html#pos-tagging",
    "title": "Pipeline para el Procesamiento del Lenguaje Natural (NPL) a través de la librería spaCy",
    "section": "2.4 POS Tagging",
    "text": "2.4 POS Tagging\nPart of speech.\nEtiqueta las palabras de un texto determinado según sus respectivos tipos de palabras, como sustantivos, adjetivos, adverbios y verbos.\nEl etiquetado POS es el proceso de identificar la categoría gramatical (como verbo, sustantivo, adjetivo, etc.) de cada palabra en una oración.\nLas etiquetas que spaCy utiliza se basan en el trabajo realizado por Universal Dependencies, un repositorio común que se puede utilizar para entrenar modelos como spaCy. La página de Dependencias universales tiene información sobre los corpus disponibles para cada idioma.\nLas etiquetas (atributos del token) que spaCy crea para cada token podemos encontrarlas en https://spacy.io/api/token#attributes.\nMerece la pena prestar especial atención al atributo pos_, que nos permitirá encontrar palabras según su categoría gramatical.\n \n\n Universal POS tags \n\nEjemplo.\n\n\nCódigo\nprint(\"Token:\", nlp(text)[0])\n\n\nToken: Capítulo\n\n\n\npropiedades = ['text', 'lang_', 'pos_', 'is_digit', 'is_lower', 'is_upper', 'is_sent_start', 'is_sent_end',\n               'like_email', 'like_url', # Espero no encontrar ninguna de estas etiquetas en El Quijote\n               'sentiment', 'sent']\n\n\n\nCódigo\nejemplo_01 = nlp(text)[0]\n\nfor attr in propiedades:\n    print(\"obj.%s = %r\" % (attr, getattr(ejemplo_01, attr)))\n\n\nobj.text = 'Capítulo'\nobj.lang_ = 'es'\nobj.pos_ = 'PROPN'\nobj.is_digit = False\nobj.is_lower = False\nobj.is_upper = False\nobj.is_sent_start = True\nobj.is_sent_end = False\nobj.like_email = False\nobj.like_url = False\nobj.sentiment = 0.0\nobj.sent = Capítulo primero.\n\n\nEjemplo.\n\n\nCódigo\nejemplo_02 = nlp(re.sub(r'[^\\w\\s]', '', text))[:15]\n\n# Encabezado\nprint(f'{\"text\":&lt;12} {\"lemma_\":&lt;12}{\"pos\":&lt;12}{\"pos_\":&lt;12}{\"tag_\":&lt;12}{\"dep_\":&lt;12}{\"shape_\":&lt;12}{\"is_alpha\":&lt;12}{\"is_stop\":&lt;12}')\nprint(\"=\"*12*9)\n\n# Loop que imprime los datos en formato de tabla\nfor token in ejemplo_02:\n    print(f'{token.text:&lt;12} {token.lemma_:&lt;11} {token.pos:&lt;11} {token.pos_:&lt;11} {token.tag_:&lt;11} {token.dep_:&lt;12}'\n          f'{token.shape_:&lt;11} {token.is_alpha:&lt;11} {token.is_stop:&lt;11}')\n\n\ntext         lemma_      pos         pos_        tag_        dep_        shape_      is_alpha    is_stop     \n============================================================================================================\nCapítulo     Capítulo    96          PROPN       PROPN       nsubj       Xxxxx       1           0          \nprimero      primero     84          ADJ         ADJ         advmod      xxxx        1           1          \nQue          Que         98          SCONJ       SCONJ       nsubj       Xxx         1           1          \ntrata        tratar      100         VERB        VERB        acl         xxxx        1           1          \nde           de          85          ADP         ADP         case        xx          1           1          \nla           el          90          DET         DET         det         xx          1           1          \ncondición    condición   92          NOUN        NOUN        obj         xxxx        1           0          \ny            y           89          CCONJ       CCONJ       cc          x           1           1          \nejercicio    ejercicio   92          NOUN        NOUN        conj        xxxx        1           0          \ndel          del         85          ADP         ADP         case        xxx         1           1          \nfamoso       famoso      84          ADJ         ADJ         amod        xxxx        1           0          \nhidalgo      hidalgo     92          NOUN        NOUN        nmod        xxxx        1           0          \n\n           \n          103         SPACE       SPACE       dep         \n          0           0          \ndon          don         92          NOUN        NOUN        appos       xxx         1           0          \nQuijote      Quijote     96          PROPN       PROPN       flat        Xxxxx       1           0          \n\n\n\n2.4.1 Selección de nombres\nEn nuestro ejemplo anterior:\n\n\nCódigo\nnouns = []\nfor token in ejemplo_02:\n    if token.pos_ == 'NOUN':\n        nouns.append(token.lemma_)\n\nnouns_total = Counter(nouns)\n\ndf = pd.DataFrame(nouns_total.most_common(), columns=['noun', 'count'])\ndf.style.hide(axis=\"index\")\n\n\n\n\n\n\n\nnoun\ncount\n\n\n\n\ncondición\n1\n\n\nejercicio\n1\n\n\nhidalgo\n1\n\n\ndon\n1\n\n\n\n\n\nEn nuestro texto completo:\n\n\nCódigo\nnouns = []\nfor token in nlp(text):\n    if token.pos_ == 'NOUN':\n        nouns.append(token.lemma_)\n\nnouns_total = Counter(nouns)\n\ndf = pd.DataFrame(nouns_total.most_common(), columns=['token', 'frecuencia'])\ndf[:5].style.hide(axis=\"index\")\n\n\n\n\n\n\n\ntoken\nfrecuencia\n\n\n\n\ncaballero\n61\n\n\ndon\n56\n\n\nlibro\n48\n\n\nseñor\n38\n\n\ncura\n33\n\n\n\n\n\n\n\n2.4.2 Selección de cualqueir categoría gramatical\nConsultamos la Universal POS tags y definimos la categoría que queremos extraer.\n\ncategoria = 'ADV'\n\n\n\nCódigo\nlista_categoria = []\nfor token in nlp(text):\n    if token.pos_ == categoria:\n        lista_categoria.append(token.lemma_)\n\ncategoria_total = Counter(lista_categoria)\n\ndf = pd.DataFrame(categoria_total.most_common(), columns=['token', 'frecuencia'])\ndf[:5].style.hide(axis=\"index\")\n\n\n\n\n\n\n\ntoken\nfrecuencia\n\n\n\n\nno\n186\n\n\nmás\n61\n\n\ntanto\n50\n\n\nasí\n44\n\n\nmucho\n33"
  },
  {
    "objectID": "index.html#ner",
    "href": "index.html#ner",
    "title": "Pipeline para el Procesamiento del Lenguaje Natural (NPL) a través de la librería spaCy",
    "section": "2.5 NER",
    "text": "2.5 NER\nNamed-Entity Recognition.\nNER es el proceso de identificar entidades nombradas (como nombres de personas, lugares, organizaciones, etc.) en un texto. La biblioteca spaCy es particularmente útil para esta tarea.\nCada modelo de la librería spaCy tiene sus propias entidades, que se encuentran en la sección Label Scheme de la documentación del modelo. Para modelo cargado las entidades se almacenan con las etiqetas LOC, ORG, PER y MISC. (lugares, organizacoines, personas y un comodín para las tres anteriores)\n\n\nCódigo\n#code-fold: false\ngetattr(nlp.get_pipe('ner'), 'labels')\n\n\n('LOC', 'MISC', 'ORG', 'PER')\n\n\nTodas las entidades nombradas se encuentran en la propiedad document.ents.\n\ndocumento = nlp(text)\n\n\n\nCódigo\nfor named_entity in list(documento.ents)[:10]:\n    print(named_entity, named_entity.label_)\n\n\nQue trata de la condición MISC\nhidalgo PER\nla Mancha LOC\nUna olla de algo más vaca MISC\nEl resto della MISC\nTenía en su casa una MISC\nFrisaba LOC\nQuieren PER\nQuijada PER\nQuesada LOC\n\n\n\n2.5.1 Búsqueda de una entidad en el documento\nPodemos encontrar una entidad dentro de su propio contexto.\niba aquí\n\n\nCódigo\nget_ner_in_context('hidalgo', nlp(quijote), desired_ner_labels = False)\n\n\nResultado 1.\n\n\nTipo de entidad: PER\n\n\nContexto:\n\n\nQue trata de la condición y ejercicio del famoso hidalgo don Quijote de la Mancha En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor.\n\n\nResultado 2.\n\n\nTipo de entidad: PER\n\n\nContexto:\n\n\nEl labrador estaba admirado oyendo aquellos disparates; y, quitándole la visera, que ya estaba hecha pedazos de los palos, le limpió el rostro, que le tenía cubierto de polvo; y apenas le hubo limpiado, cuando le conoció y le dijo: — Señor Quijana —que así se debía de llamar cuando él tenía juicio y no había pasado de hidalgo sosegado a caballero andante—, ¿quién ha puesto a vuestra merced desta suerte? Pero él seguía con su romance a cuanto le preguntaba.\n\n\nResultado 3.\n\n\nTipo de entidad: PER\n\n\nContexto:\n\n\nA esto respondió el labrador: — Mire vuestra merced, señor, pecador de mí, que yo no soy don Rodrigo de Narváez, ni el marqués de Mantua, sino Pedro Alonso, su vecino; ni vuestra merced es Valdovinos, ni Abindarráez, sino el honrado hidalgo del señor Quijana.\n\n\n\n\n2.5.2 Visualizers\nhttps://spacy.io/usage/visualizers\nPodemos usar sus demos online que actualmente usan la versión small del modelo en español.\n\nhttps://demos.explosion.ai/displacy\nhttps://demos.explosion.ai/displacy-ent\n\n\n2.5.2.1 Dependency parse\nAnálisis sintáctico de dependencia. Es el visualizador por defecto si no especificamos ningún estilo.\nVisualizamos el texto Cuando Mario empezó a trabajar en este pipeline, poca gente imaginaba el alcance. como ejemplo.\n\n# options: https://spacy.io/api/top-level#options-dep\noptions = {\"compact\": True,\n           \"color\": \"green\",\n           \"bg:\": \"red\", # no hace caso\n           \"arrow_width\": 5,\n           \"word_spacing\": 20,\n           \"distance\": 120}\n\ndoc = nlp(text_for_visual)\ndisplacy.render(doc, options=options) # = displacy.render(doc, style=\"dep\")\n\n\n\n    Cuando\n    SCONJ\n\n\n\n    Mario\n    PROPN\n\n\n\n    empezó\n    VERB\n\n\n\n    a\n    ADP\n\n\n\n    trabajar\n    VERB\n\n\n\n    en\n    ADP\n\n\n\n    este\n    DET\n\n\n\n    pipeline,\n    NOUN\n\n\n\n    poca\n    DET\n\n\n\n    gente\n    NOUN\n\n\n\n    imaginaba\n    VERB\n\n\n\n    el\n    DET\n\n\n\n    alcance.\n    NOUN\n\n\n\n    \n    \n        mark\n    \n    \n\n\n\n    \n    \n        nsubj\n    \n    \n\n\n\n    \n    \n        advcl\n    \n    \n\n\n\n    \n    \n        mark\n    \n    \n\n\n\n    \n    \n        xcomp\n    \n    \n\n\n\n    \n    \n        case\n    \n    \n\n\n\n    \n    \n        det\n    \n    \n\n\n\n    \n    \n        obl\n    \n    \n\n\n\n    \n    \n        det\n    \n    \n\n\n\n    \n    \n        nsubj\n    \n    \n\n\n\n    \n    \n        det\n    \n    \n\n\n\n    \n    \n        obj\n    \n    \n\n\n\n\n\n\n2.5.2.2 Entity recognizer\nVisualizando el reconocedor de entidades.\nUsamos dos modelos distintos. Cada uno cuenta con sus propias entidades identificadas en el Label Scheme de cada modelo.\nVisualizamos el texto María se fue en 2020 al río Guadiana a pescar peces coloridos mientras Mario iban a por bebida al supermercado Mercado. como ejemplo.\n\nEl primer modelo, es_core_news_md, el que hemos estado usando hasta ahora. Con cuatro entidades NER: LOC, MISC, ORG y PER.\n\n\n# options: https://spacy.io/api/top-level#displacy_options-ent\n\ncolors = {\"PER\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\",\n          \"LOC\": \"linear-gradient(90deg, orange, lightblue)\"}\noptions = {#\"ents\": [\"PER\"], # si quisiéramos especificar las entidades que queremos mostrar\n           \"colors\": colors}\n\ndoc = nlp(text_for_visual)\n#displacy.server(doc, style=\"ent\", options=options, auto_select_port=True)\ndisplacy.render(doc, style=\"ent\", options=options)\n\n\n\n    María\n    PER\n\n se fue en 2020 al río \n\n    Guadiana\n    LOC\n\n a pescar peces coloridos mientras \n\n    Mario\n    PER\n\n iban a por bebida al supermercado \n\n    Mercado\n    LOC\n\n.\n\n\n\nEl segundo modelo, en_core_web_sm, en inglés. Con muchas más entidades con NER: CARDINAL, DATE, …, WORK_OF_ART\n\n\n# options: https://spacy.io/api/top-level#displacy_options-ent\n\ncolors = {\"PERSON\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\",\n          \"DATE\": \"linear-gradient(90deg, white, green)\",\n          \"GPE\": \"linear-gradient(90deg, orange, lightblue)\"}\noptions = {#\"ents\": [\"PER\"], # si quisiéramos especificar las entidades que queremos mostrar\n           \"colors\": colors}\n\nnlp_en = spacy.load(\"en_core_web_sm\")\ndoc = nlp_en(text_for_visual)\ndisplacy.render(doc, style=\"ent\", options=options)\n\n\n\n    María se fue\n    PERSON\n\n en \n\n    2020\n    DATE\n\n \n\n    al río Guadiana\n    PERSON\n\n a pescar peces coloridos mientras \n\n    Mario\n    PERSON\n\n iban a por bebida \n\n    al supermercado Mercado\n    PERSON\n\n.\n\n\n\n\n\n2.5.3 Selección de un tipo de entidad\nPodemos identificar el tipo de entidades que queremos buscar.\nEjemplo.\nLOC\n\n\nCódigo\nprint(f\"{nlp(text).ents[2]} - {repr(nlp(text).ents[2].label_)}\")\n\n\nla Mancha - 'LOC'\n\n\nEjemplo.\nPER\n\n\nCódigo\npers = []\nfor named_entity in nlp(text).ents:\n    if named_entity.label_  == 'PER':\n        pers.append(named_entity.lemma_)\n\npers_total = Counter(pers)\n\ndf = pd.DataFrame(pers_total.most_common(), columns=['named_entity', 'frecuencia'])\ndf[:6]\n\n\n\n\n\n\n\n\n\nnamed_entity\nfrecuencia\n\n\n\n\n0\nAndrés\n7\n\n\n1\nNicolás\n5\n\n\n2\nseñor caballero\n5\n\n\n3\nAmadís de Gaula\n4\n\n\n4\nAmadís\n4\n\n\n5\nRocinante\n4\n\n\n\n\n\n\n\n\n\n2.5.4 Diferencia entre POS y NER\nPodemos ver la diferencia entre POS y NER con el siguiente ejemplo.\nEjemplo.\nMaría se fue en 2020 al río Guadiana a pescar peces coloridos mientras Mario iban a por bebida al supermercado Mercado.\n\n\nCódigo\npropiedades = ['text', 'pos_']\n\nprint('POS')\nfor token in ejemplo[:6]:\n    print('---')\n    for attr in propiedades:\n        print(\"obj.%s = %r\" % (attr, getattr(token, attr)))\n\n\nprint('NER')\nprint('---')\nfor named_entity in list(ejemplo.ents):\n   print(f\"{named_entity} - label: {repr(named_entity.label_)}\")\n\n\n\n\n\n\n    \n        POS---obj.text = 'María'obj.pos_ = 'PROPN'---obj.text = 'se'obj.pos_ = 'PRON'---obj.text = 'fue'obj.pos_ = 'VERB'---obj.text = 'en'obj.pos_ = 'ADP'---obj.text = '2020'obj.pos_ = 'NOUN'---obj.text = 'al'obj.pos_ = 'ADP'\n    \n    \n        NER---María - label: 'PER'Guadiana - label: 'LOC'Mario - label: 'PER'Mercado - label: 'LOC'"
  }
]