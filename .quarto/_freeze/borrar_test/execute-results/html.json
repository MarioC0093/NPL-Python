{
  "hash": "f21b2357e0f9698937436ea286dd803c",
  "result": {
    "markdown": "---\ntitle: \"NPL with Python\"\nauthor: \"Mario Camacho\"\ndate: \"xx-xx-2024\"\ndate-modified: last-modified\ndate-format: \"DD MMMM YYYY\"\nlang: es\n\nexecute:\n    enabled: true\n---\n\n## Librerías\n\n::: {.cell execution_count=1}\n``` {.python .cell-code code-fold=\"false\"}\n# Import text from url\nimport requests\nimport re\n# Tokenizacion\nimport nltk\nfrom nltk.tokenize import word_tokenize\n# Stop Words\nfrom nltk.corpus import stopwords\n# Steamming and Lemmatization\nimport nltk\nfrom nltk.stem.snowball import SnowballStemmer\n```\n:::\n\n\n# Quijote\n\nLeemos el libro El Quijote.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Enviar una solicitud GET a la URL\nresponse = requests.get(\"https://www.gutenberg.org/cache/epub/2000/pg2000.txt\")\n\n# Verificar si la solicitud fue exitosa\nif response.status_code == 200:\n    quijote = response.text\n    # print(\"Éxito al leer el texto.\")\nelse:\n    print(\"Error al leer el texto.\")\n\n```\n:::\n\n\nNos ocupamos únicamente de los primeros seis capítulos de la primera parte de El Quijote.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Palabra objetivo\npalabra = \"Primera parte del ingenioso hidalgo don Quijote de la Mancha\"\n\n# Expresión regular para capturar todo lo que va antes de la aparición de \"Capítulo primero\"\npatron = re.compile(rf\"{palabra}\\s*(.*)\", re.DOTALL)\n\n# Realizamos la búsqueda\ncoincidencia = patron.search(quijote)\n\nif coincidencia:\n    quijote = coincidencia.group(1) # 0 incluye la palabra del search, 1 no lo incluye\n    print(\"Inicio del texto:\\n\\n\", quijote[:251])\nelse:\n    print(\"Inicio del texto:\\n\\n\", quijote[:251])\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nInicio del texto:\n\n Capítulo primero. Que trata de la condición y ejercicio del famoso hidalgo\r\ndon Quijote de la Mancha\r\n\r\nEn un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho\r\ntiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua\n```\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\npalabra = \"Capítulo VI\"\n\n# patron = re.compile(rf\"(.*)\\b{re.escape(palabra)}\\b\", re.DOTALL) # .* es codicioso (\"greedy\"): captura la mayor cantidad posible de caracteres antes de la coincidir con la palabra, captura hasta la última aparición de la palabra buscada\npatron = re.compile(rf\"(.*?)\\b{re.escape(palabra)}\\b\", re.DOTALL) # .* es no codicioso (\"lazy\"): captura la menor cantidad posible de caracteres y evitar que el resto del texto cooincida, se detiene en la primera coincidencia\n\n# Realizamos la búsqueda\ncoincidencia = patron.search(quijote)\n\nif coincidencia:\n    quijote = coincidencia.group(0)\n    print(\"Final del texto:\\n\\n\", quijote[-231:])\n    quijote = coincidencia.group(1) # Elimino el patrón de búsqueda\nelse:\n    print(\"Final del texto:\\n\\n\", quijote[-231:])  \n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFinal del texto:\n\n que al hallarle y al traerle había dicho; que fue poner más\r\ndeseo en el licenciado de hacer lo que otro día hizo, que fue llamar a su\r\namigo el barbero maese Nicolás, con el cual se vino a casa de don Quijote,\r\n\r\n\r\n\r\n\r\nCapítulo VI\n```\n:::\n:::\n\n\n# Pipeline NPL\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ntext = quijote\n```\n:::\n\n\n## Tokenization\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ntokens = word_tokenize(text)\nprint(tokens[:10])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['Capítulo', 'primero', '.', 'Que', 'trata', 'de', 'la', 'condición', 'y', 'ejercicio']\n```\n:::\n:::\n\n\n## Stop Words\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nstop_words = set(stopwords.words('spanish'))\ntokens = [w for w in tokens if w.lower() not in stop_words]\nprint(tokens[:10])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['Capítulo', 'primero', '.', 'trata', 'condición', 'ejercicio', 'famoso', 'hidalgo', 'don', 'Quijote']\n```\n:::\n:::\n\n\n## Stemming and Lemmatization\n\nhttps://spacy.io/models/es  \nhttps://github.com/explosion/spacy-models/releases?q=es_core_web_md&expanded=true\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# %pip install -U spacy\n```\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nstemmer = SnowballStemmer(\"spanish\")\n\ntokens = [stemmer.stem(palabra) for palabra in tokens]\n\ntokens[:10]\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```\n['capitul',\n 'primer',\n '.',\n 'trat',\n 'condicion',\n 'ejercici',\n 'famos',\n 'hidalg',\n 'don',\n 'quijot']\n```\n:::\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n# %python -m spacy download es_core_news_md\n```\n:::\n\n\n\n# Instalación de librerías necesarias\n!python -m spacy download en_core_web_sm\n%pip install nltk spacy textblob\n\n# Importar librerías\nimport nltk\nimport spacy\nfrom textblob import TextBlob\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\n# Descargar recursos necesarios\nnltk.download('punkt')\nnltk.download('stopwords')\nimport spacy\nfrom spacy.lang.en.examples import sentences\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Texto de ejemplo\ntexto = \"Apple is looking at buying U.K. startup for $1 billion. The company is highly praised by analysts.\"\n\n# Preprocesamiento con NLTK: Tokenización y eliminación de stopwords\nnltk.download('punkt_tab')\ntokens = word_tokenize(texto)\nstop_words = set(stopwords.words('english'))\nfiltered_tokens = [word for word in tokens if word.lower() not in stop_words]\nprint(\"Tokens filtrados:\", filtered_tokens)\n\n# Análisis de entidades nombradas con spaCy\ndoc = nlp(texto)\nfor ent in doc.ents:\n    print(ent.text, ent.label_)\n\n# Análisis de sentimientos con TextBlob\nblob = TextBlob(texto)\nsentimiento = blob.sentiment\n\nprint(\"Análisis de sentimiento:\", sentimiento)\n\n",
    "supporting": [
      "borrar_test_files"
    ],
    "filters": [],
    "includes": {}
  }
}